{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!add-apt-repository -y ppa:jonathonf/ffmpeg-4\n",
    "!apt update\n",
    "!apt install -y ffmpeg\n",
    "\n",
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install gradio\n",
    "!pip install hopsworks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## login huggingface and hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "# 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\n",
    "\n",
    "import hopsworks\n",
    "project = hopsworks.login()\n",
    "# T1aiPJzBrcYM1mzh.92B50IDnHkgHGljiOTS72KNPeaxWW8orYFF2YjyjfqmZdpI6ASKg9xRu0oYIbMM0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"train+validation\", use_auth_token=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"zh-CN\", split=\"test\", use_auth_token=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove useless informaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Feature Extractor, Tokenizer and Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create A WhisperProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Chinese\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Chinese\", task=\"transcribe\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice.save_to_disk(\"common_voice\")\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/dataset_dict.json\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/train/state.json\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/train/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/train/dataset_info.json\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/train/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/train/dataset.arrow\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/train/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/test/state.json\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/test/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/test/dataset.arrow\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/test/\", overwrite=True)\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\n",
    "    local_path = \"./common_voice/test/dataset_info.json\", \n",
    "    upload_path = \"fsorg_Training_Datasets/common_voice/test/\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f792530c90cda680124397377fd9d6eea4de4d531d03b3898f1d5506fa2e7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
